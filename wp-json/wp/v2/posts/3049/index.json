{"id":3049,"date":"2025-11-20T10:34:28","date_gmt":"2025-11-20T09:34:28","guid":{"rendered":"\/?p=3049"},"modified":"2025-11-20T10:35:29","modified_gmt":"2025-11-20T09:35:29","slug":"ai-agents-advance-atomic-force-microscopy-automation","status":"publish","type":"post","link":"\/2025\/11\/20\/ai-agents-advance-atomic-force-microscopy-automation\/","title":{"rendered":"AI agents advance atomic force microscopy automation: new benchmark reveals capabilities and critical safety concerns"},"content":{"rendered":"\n<div class=\"wp-block-columns alignwide is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\">\n<div class=\"wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\">\n<p>New research published in <em>Nature Communications<\/em> by Mandal et al. (Indian Institute of Technology Delhi, India) presents a comprehensive evaluation of large language model agents for automating atomic force microscopy. The researchers developed AILA (Artificially Intelligent Lab Assistant) and AFMBench to assess the potential and limitations of AI-powered laboratory automation.<\/p>\n\n\n\n<p>Atomic force microscopy (AFM) is a powerful materials characterization technique with applications across nanotechnology, materials science, and biology, but it requires significant expertise to operate effectively. Traditional approaches demand manual parameter optimization, careful experimental design, and expert interpretation of results. When conducting complex experimental workflows, this expertise requirement can become a bottleneck, limiting throughput and accessibility. Ultimately, this restricts AFM\u2019s broader adoption in research and industry.<\/p>\n\n\n\n<p>The new work implements a multi-agent AI framework that can interpret natural language queries and autonomously orchestrate the complete AFM workflow\u2014from experimental design and instrument calibration to imaging, data analysis, and decision-making. AILA employs specialized agents coordinated by a central planner: the AFM Handler Agent controls experimental operations while the Data Handler Agent manages analysis and optimization. The system is evaluated using AFMBench, a suite of 100 real-laboratory tasks covering the full spectrum of microscopy operations, providing a rigorous benchmark for AI agents in experimental contexts.<\/p>\n\n\n\n<p>In the work, the researchers evaluated four leading language models (GPT-4o, GPT-3.5, Claude-3.5-sonnet, and Llama-3.3) across AFMBench and demonstrated AILA&#8217;s capabilities through five real-world experiments: automated microscope calibration through PID parameter optimization; high-resolution detection of graphene step edges at the atomic scale requiring sophisticated baseline correction; load-dependent friction measurements on highly oriented pyrolytic graphite with automated data plotting; identification and layer counting of graphene flakes on silicon substrates through autonomous feature detection; and analysis of indentation marks to infer indenter geometry. Overall, the applications prove the potential of AI agents for laboratory automation while revealing critical limitations: GPT-4o achieved 65% success on benchmark tasks but struggled with code generation errors; models excelling at materials science knowledge performed poorly in hands-on tasks, showing domain knowledge doesn\u2019t translate to experimental capabilities; and critically, AI agents sometimes \u201csleepwalk\u201d\u2014deviating from instructions to perform unintended and potentially dangerous actions, raising serious safety concerns for autonomous laboratory deployment. The multi-agent architecture significantly outperformed single-agent approaches, though both remained sensitive to instruction phrasing. Importantly, this work establishes the first comprehensive benchmark for evaluating AI laboratory assistants and provides essential safety insights for the emerging field of self-driving laboratories.<\/p>\n\n\n\n<p><\/p>\n<\/div>\n<\/div>\n<\/div>\n<\/div>\n\n\n\n<div class=\"wp-block-group has-base-color has-light-blue-background-color has-text-color has-background has-link-color wp-elements-bfa8b8e8a5a23ff70c54517ecc657a6d\" style=\"padding-top:var(--wp--preset--spacing--20);padding-right:var(--wp--preset--spacing--40);padding-bottom:var(--wp--preset--spacing--20);padding-left:var(--wp--preset--spacing--40)\"><div class=\"wp-block-group__inner-container is-layout-constrained wp-container-core-group-is-layout-26f58b4f wp-block-group-is-layout-constrained\">\n<h4 class=\"wp-block-heading has-black-color has-text-color has-link-color wp-elements-cfc1229d547209fd523665ae8d1c3e35\">More information:<\/h4>\n\n\n\n<p>For the complete benchmark suite and code, see <a href=\"https:\/\/github.com\/M3RG-IITD\/AILA\">the repository on GitHub<\/a>. <br>Indrajeet Mandal, <em>et al<\/em>. Evaluating large language model agents for automation of atomic force microscopy. Nat Comm <strong>16<\/strong> 9104 (2025) <a href=\"https:\/\/doi.org\/10.1038\/s41467-025-64105-7\">https:\/\/doi.org\/10.1038\/s41467-025-64105-7<\/a><\/p>\n<\/div><\/div>\n","protected":false},"excerpt":{"rendered":"<p>New research published in Nature Communications by Mandal et al. (Indian Institute of Technology Delhi, India) presents a comprehensive evaluation of large language model agents for automating atomic force microscopy. The researchers developed AILA (Artificially Intelligent Lab Assistant) and AFMBench to assess the potential and limitations of AI-powered laboratory automation. Atomic force microscopy (AFM) is [&hellip;]<\/p>\n","protected":false},"author":245394738,"featured_media":3051,"comment_status":"closed","ping_status":"open","sticky":false,"template":"","format":"standard","meta":{"advanced_seo_description":"","jetpack_seo_html_title":"","jetpack_seo_noindex":false,"jetpack_post_was_ever_published":false,"_jetpack_newsletter_access":"","_jetpack_dont_email_post_to_subs":false,"_jetpack_newsletter_tier_id":0,"_jetpack_memberships_contains_paywalled_content":false,"_jetpack_memberships_contains_paid_content":false,"footnotes":"","jetpack_publicize_message":"","jetpack_publicize_feature_enabled":true,"jetpack_social_post_already_shared":true,"jetpack_social_options":{"image_generator_settings":{"template":"highway","default_image_id":0,"font":"","enabled":false},"version":2}},"categories":[91033],"tags":[],"table_tags":[],"class_list":["post-3049","post","type-post","status-publish","format-standard","has-post-thumbnail","hentry","category-press-release"],"jetpack_publicize_connections":[],"jetpack_featured_media_url":"https:\/\/i0.wp.com\/smartmicroscopy.org\/wp-content\/uploads\/2025\/11\/image_press_iitd.png?fit=1260%2C679&ssl=1","jetpack_likes_enabled":true,"jetpack_sharing_enabled":true,"jetpack_shortlink":"https:\/\/wp.me\/pfrUPs-Nb","jetpack-related-posts":[],"_links":{"self":[{"href":"\/wp-json\/wp\/v2\/posts\/3049","targetHints":{"allow":["GET"]}}],"collection":[{"href":"\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"\/wp-json\/wp\/v2\/users\/245394738"}],"replies":[{"embeddable":true,"href":"\/wp-json\/wp\/v2\/comments?post=3049"}],"version-history":[{"count":3,"href":"\/wp-json\/wp\/v2\/posts\/3049\/revisions"}],"predecessor-version":[{"id":3053,"href":"\/wp-json\/wp\/v2\/posts\/3049\/revisions\/3053"}],"wp:featuredmedia":[{"embeddable":true,"href":"\/wp-json\/wp\/v2\/media\/3051"}],"wp:attachment":[{"href":"\/wp-json\/wp\/v2\/media?parent=3049"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"\/wp-json\/wp\/v2\/categories?post=3049"},{"taxonomy":"post_tag","embeddable":true,"href":"\/wp-json\/wp\/v2\/tags?post=3049"},{"taxonomy":"table_tags","embeddable":true,"href":"\/wp-json\/wp\/v2\/table_tags?post=3049"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}